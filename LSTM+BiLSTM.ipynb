{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Full_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFZsj2EgB4VY",
        "colab_type": "code",
        "outputId": "a2d172d7-cebc-4873-c16d-24ed2687dba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAwWXEROCKjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = pd.read_csv(\"/content/drive/Shared drives/EMNLP/full_prepped_training.csv\")\n",
        "test_file = pd.read_csv(\"/content/drive/Shared drives/EMNLP/prepped_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDF08fZYCpW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# original; edited_sentence; word_position; cosine_similarity\n",
        "def dataset_gathering(dataset):\n",
        "    # origin = dataset[\"original\"]\n",
        "    edited = dataset[\"edited_sentence\"]\n",
        "    labels = dataset[\"meanGrade\"]\n",
        "    # position = dataset[\"word_position\"]\n",
        "    # cosine = dataset[\"cosine_similarity\"]\n",
        "\n",
        "    res = []\n",
        "    for sample in zip(edited, labels):\n",
        "        res.append(sample)\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE56chFYCqxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = dataset_gathering(train_file)\n",
        "test_file = dataset_gathering(test_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szuVrDQ3Cw1Q",
        "colab_type": "code",
        "outputId": "eb1e8a84-fcbc-413e-eed9-89b73c39b725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_file))\n",
        "print(len(test_file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17900\n",
            "3024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG4Zb18hC1o3",
        "colab_type": "code",
        "outputId": "54352516-cd54-4c70-8d48-226a073c970b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(train_file[0])\n",
        "print(test_file[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('France is ‘ hunting down its citizens who joined twins ’ without trial in Iraq', 0.2)\n",
            "('The Latest : Election tally shows Cars turning right', 1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG5NorhiC6YC",
        "colab_type": "code",
        "outputId": "06adc757-3760-4fd9-c74c-dc50f7f8669f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('Tokenizeing...')\n",
        "print('\\n')\n",
        "\n",
        "def tokenize(data):\n",
        "    res = []\n",
        "    for samples in data:\n",
        "        # nltk.word_tokenize用于取tokens\n",
        "        temp_t = nltk.word_tokenize(samples[0])\n",
        "        res.append([temp_t, samples[1]])\n",
        "    return res\n",
        "\n",
        "\n",
        "train_file = tokenize(train_file)\n",
        "test_file = tokenize(test_file)\n",
        "print(train_file[0])\n",
        "print(test_file[0])\n",
        "print('\\n')\n",
        "print('Tokenization completed!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizeing...\n",
            "\n",
            "\n",
            "[['France', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'Iraq'], 0.2]\n",
            "[['The', 'Latest', ':', 'Election', 'tally', 'shows', 'Cars', 'turning', 'right'], 1.2]\n",
            "\n",
            "\n",
            "Tokenization completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ERDxq1FDHIv",
        "colab_type": "code",
        "outputId": "73a96d64-53ee-45d3-c7cc-4da80fc39c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "def lower_case(data):\n",
        "  print('-----Converting to lowercases-----')\n",
        "  res = []\n",
        "  temp_words = []\n",
        "  for samples in data:\n",
        "    for words in samples[0]:\n",
        "      temp_words.append(words.lower())\n",
        "    res.append([temp_words, samples[1]])\n",
        "    temp_words = []\n",
        "  print('-----Complete!-----')\n",
        "  return res\n",
        "\n",
        "train_file = lower_case(train_file)\n",
        "test_file = lower_case(test_file)\n",
        "print(train_file[0])\n",
        "print(test_file[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Converting to lowercases-----\n",
            "-----Complete!-----\n",
            "-----Converting to lowercases-----\n",
            "-----Complete!-----\n",
            "[['france', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'iraq'], 0.2]\n",
            "[['the', 'latest', ':', 'election', 'tally', 'shows', 'cars', 'turning', 'right'], 1.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO9C77mqDORk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cacluating maxlen\n",
        "def maxlen_cal(data):\n",
        "  print('-----Cacluating maxlen-----')\n",
        "  maxlen = 0\n",
        "  for samples in data:\n",
        "    temp = len(samples[0])\n",
        "    if temp >= maxlen:\n",
        "      maxlen = temp\n",
        "  print('-----Complete!-----')\n",
        "  return maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8l3YKR9DQjw",
        "colab_type": "code",
        "outputId": "6d6163ba-a320-4cd3-b02b-6247ac6bc6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(maxlen_cal(train_file))\n",
        "print(maxlen_cal(test_file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "29\n",
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgklkdU-DUKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoGpP8sHDWX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding_len(data, maxlen):\n",
        "  print('-----Padding for dataset-----')\n",
        "  maxlen = maxlen\n",
        "  res = []\n",
        "  for samples in data:\n",
        "    temp_len = len(samples[0])\n",
        "    for k in range(maxlen - temp_len):\n",
        "      samples[0].append('.')\n",
        "    res.append([samples[0], samples[1]])\n",
        "  print('-----Complete!-----')\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3GqJENHDYD7",
        "colab_type": "code",
        "outputId": "a8a16a5a-2e7d-4844-fc32-4636da9435fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_file = padding_len(train_file, maxlen)\n",
        "test_file = padding_len(test_file, maxlen)\n",
        "\n",
        "print(maxlen_cal(train_file))\n",
        "print(maxlen_cal(test_file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Padding for dataset-----\n",
            "-----Complete!-----\n",
            "-----Padding for dataset-----\n",
            "-----Complete!-----\n",
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "30\n",
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AST3IkFDgz8",
        "colab_type": "code",
        "outputId": "914ebeb6-e3fe-45f1-a63b-70c64de8d598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(train_file[0])\n",
        "print(test_file[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['france', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'iraq', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.'], 0.2]\n",
            "[['the', 'latest', ':', 'election', 'tally', 'shows', 'cars', 'turning', 'right', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.'], 1.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-HLynjVDnwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def corpus_labels_gathering(data):\n",
        "  corpus_res = []\n",
        "  labels_res = []\n",
        "  for samples in data:\n",
        "    corpus_res.append(samples[0])\n",
        "    labels_res.append(samples[1])\n",
        "    \n",
        "  labels_res = np.array(labels_res)\n",
        "  return corpus_res, labels_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLZBxFIKDpnM",
        "colab_type": "code",
        "outputId": "7d36f17b-7f47-4388-fe4c-8ed172a0ff71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "x_train, y_train = corpus_labels_gathering(train_file)\n",
        "x_test, y_test = corpus_labels_gathering(test_file)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(x_train[0])\n",
        "print(x_test[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17900,)\n",
            "(3024,)\n",
            "['france', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'iraq', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['the', 'latest', ':', 'election', 'tally', 'shows', 'cars', 'turning', 'right', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hntVMgzlDuCS",
        "colab_type": "code",
        "outputId": "a55b8d77-4287-4878-d0a8-1e358ad13009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = os.path.join('/content/drive/', 'My Drive')\n",
        "embedding_dim = 300\n",
        "# Dictionary where we store the word:vector_embedding map\n",
        "embeddings_index = {}\n",
        "word_index = {}\n",
        "count=0\n",
        "\n",
        "# Setting up embedding array\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.300d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float64')\n",
        "    if coefs.shape[0] != embedding_dim:\n",
        "      continue\n",
        "    # Embeddings is a dictionary of words:word_vector_embeddings\n",
        "    embeddings_index[word] = coefs\n",
        "    word_index[word] = count\n",
        "    count+=1\n",
        "f.close()\n",
        "print('Found {} word vectors.'.format(len(embeddings_index)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gkNHN3Dvyb",
        "colab_type": "code",
        "outputId": "144b1241-9d45-4c92-a658-38f33cda566b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print('Our word index dictionary is given by: (word, index), a sample 10 entries are:')\n",
        "list(word_index.items())[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our word index dictionary is given by: (word, index), a sample 10 entries are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0),\n",
              " (',', 1),\n",
              " ('.', 2),\n",
              " ('of', 3),\n",
              " ('to', 4),\n",
              " ('and', 5),\n",
              " ('in', 6),\n",
              " ('a', 7),\n",
              " ('\"', 8),\n",
              " (\"'s\", 9)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ciOyWvxDw4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oov = \"OOV\"\n",
        "\n",
        "def oov_vec_gathering(embedding_dim):\n",
        "  res = np.random.rand(1, embedding_dim)\n",
        "  return res\n",
        "\n",
        "oov_vec = oov_vec_gathering(embedding_dim = embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDdGKD1MDyFL",
        "colab_type": "code",
        "outputId": "92e91dd8-104a-4b15-d234-9f9f94084908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index[oov] = oov_vec\n",
        "word_index[oov] = count + 1\n",
        "count += 1\n",
        "print('Found {} word vectors.'.format(len(embeddings_index)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3MoX6GaDzWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Preprocessing the GloVe word-embeddings matrix --\n",
        "max_words = count\n",
        "# Instantiating a 10000 x 100 matrix \n",
        "# embedding_matrix = (number_words, dim_embedding)\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    # Make sure that we are not exceeding the max token size\n",
        "    if i < max_words:\n",
        "        # Get the embedded vector for the word\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        # Provided that a word is known store it in the \n",
        "        # embeddig matrix at position i\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gotike4aD0ec",
        "colab_type": "code",
        "outputId": "d10b5165-78f3-4869-f666-27f3bcec620c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The size of the word embedding matrix is:\" + str(embedding_matrix.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the word embedding matrix is:(400001, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrNl6bHGD1gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2vec(data):\n",
        "  res = []\n",
        "  for samples in data:\n",
        "    for items in samples:\n",
        "      if items not in embeddings_index.keys():\n",
        "        word_index[items] = count\n",
        "      res.append(word_index[items])\n",
        "\n",
        "  res = np.array(res)\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvuNzcnBD27V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = data2vec(x_train)\n",
        "x_test = data2vec(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9DGSuvbD38l",
        "colab_type": "code",
        "outputId": "770d8a04-bc86-4c73-84c0-5ceb55cc0287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = x_train.reshape(-1, maxlen)\n",
        "x_test = x_test.reshape(-1, maxlen)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17900, 30)\n",
            "(3024, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvyGR2oVEt7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.Sequential([\n",
        "#         keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=True),\n",
        "#         keras.layers.Bidirectional(keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True)),\n",
        "#         keras.layers.Dropout(0.5),\n",
        "#         keras.layers.Dense(1024),\n",
        "#         keras.layers.LeakyReLU(alpha=0.3),\n",
        "#         keras.layers.Dropout(0.5),\n",
        "#         keras.layers.Dense(512),\n",
        "#         keras.layers.LeakyReLU(alpha=0.3),\n",
        "#         keras.layers.Dropout(0.5),\n",
        "#         keras.layers.Dense(128),\n",
        "#         keras.layers.LeakyReLU(alpha=0.2),\n",
        "#         keras.layers.Dropout(0.5),\n",
        "#         keras.layers.Dense(32), \n",
        "#         keras.layers.LeakyReLU(alpha=0.2),\n",
        "#         keras.layers.Dropout(0.5),\n",
        "#         # keras.layers.Dense(1, activation='relu')     \n",
        "#         keras.layers.Dense(1, activation=\"relu\")                \n",
        "# ])\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False),\n",
        "        # keras.layers.Bidirectional(keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=True)),\n",
        "        # keras.layers.Bidirectional(keras.layers.LSTM(1024, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=False)),\n",
        "        keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=True),\n",
        "        keras.layers.Bidirectional(keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=False)),\n",
        "        keras.layers.Dense(1024, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(512, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(32, activation='relu'), \n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(1, activation='relu')                     \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlEOd2jFE3z8",
        "colab_type": "code",
        "outputId": "bbf3612f-4bf5-4e52-cc36-0a28278d95a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 30, 300)           120000300 \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 30, 2048)          19243008  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 4096)              67125248  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 211,158,509\n",
            "Trainable params: 91,158,209\n",
            "Non-trainable params: 120,000,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ZTaO-PE4Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.adam(learning_rate=4e-5)\n",
        "# opt = keras.optimizers.sgd(learning_rate=1e-3, momentum=0.9)\n",
        "# opt = keras.optimizers.rmsprop(learning_rate=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_5agqXJE5uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=opt,\n",
        "              loss = \"mean_squared_error\",\n",
        "              metrics = ['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsa0NG5E6wp",
        "colab_type": "code",
        "outputId": "1b844840-cb31-44a2-98ef-a5f90715fc5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "            epochs = 50,\n",
        "            batch_size = 64,\n",
        "            validation_data = [x_test, y_test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17900 samples, validate on 3024 samples\n",
            "Epoch 1/50\n",
            "17900/17900 [==============================] - 318s 18ms/step - loss: 0.6543 - mse: 0.6543 - val_loss: 0.3284 - val_mse: 0.3284\n",
            "Epoch 2/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.5609 - mse: 0.5609 - val_loss: 0.3293 - val_mse: 0.3293\n",
            "Epoch 3/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.5266 - mse: 0.5266 - val_loss: 0.3173 - val_mse: 0.3173\n",
            "Epoch 4/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.5001 - mse: 0.5001 - val_loss: 0.3259 - val_mse: 0.3259\n",
            "Epoch 5/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.4772 - mse: 0.4772 - val_loss: 0.3329 - val_mse: 0.3329\n",
            "Epoch 6/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.4649 - mse: 0.4649 - val_loss: 0.3249 - val_mse: 0.3249\n",
            "Epoch 7/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.4480 - mse: 0.4480 - val_loss: 0.3206 - val_mse: 0.3206\n",
            "Epoch 8/50\n",
            "17900/17900 [==============================] - 315s 18ms/step - loss: 0.4383 - mse: 0.4383 - val_loss: 0.3127 - val_mse: 0.3127\n",
            "Epoch 9/50\n",
            "17900/17900 [==============================] - 315s 18ms/step - loss: 0.4306 - mse: 0.4306 - val_loss: 0.3138 - val_mse: 0.3138\n",
            "Epoch 10/50\n",
            "17900/17900 [==============================] - 314s 18ms/step - loss: 0.4183 - mse: 0.4183 - val_loss: 0.3222 - val_mse: 0.3222\n",
            "Epoch 11/50\n",
            "17900/17900 [==============================] - 315s 18ms/step - loss: 0.4105 - mse: 0.4105 - val_loss: 0.3134 - val_mse: 0.3134\n",
            "Epoch 12/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.4032 - mse: 0.4032 - val_loss: 0.3255 - val_mse: 0.3255\n",
            "Epoch 13/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3955 - mse: 0.3955 - val_loss: 0.3184 - val_mse: 0.3184\n",
            "Epoch 14/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3896 - mse: 0.3896 - val_loss: 0.3125 - val_mse: 0.3125\n",
            "Epoch 15/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.3769 - mse: 0.3769 - val_loss: 0.3147 - val_mse: 0.3147\n",
            "Epoch 16/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3714 - mse: 0.3714 - val_loss: 0.3174 - val_mse: 0.3174\n",
            "Epoch 17/50\n",
            "17900/17900 [==============================] - 315s 18ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 0.3154 - val_mse: 0.3154\n",
            "Epoch 18/50\n",
            "17900/17900 [==============================] - 314s 18ms/step - loss: 0.3543 - mse: 0.3543 - val_loss: 0.3160 - val_mse: 0.3160\n",
            "Epoch 19/50\n",
            "17900/17900 [==============================] - 315s 18ms/step - loss: 0.3462 - mse: 0.3462 - val_loss: 0.3294 - val_mse: 0.3294\n",
            "Epoch 20/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.3395 - mse: 0.3395 - val_loss: 0.3233 - val_mse: 0.3233\n",
            "Epoch 21/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3348 - mse: 0.3348 - val_loss: 0.3305 - val_mse: 0.3305\n",
            "Epoch 22/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3278 - mse: 0.3278 - val_loss: 0.3228 - val_mse: 0.3228\n",
            "Epoch 23/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3229 - mse: 0.3229 - val_loss: 0.3213 - val_mse: 0.3213\n",
            "Epoch 24/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.3155 - mse: 0.3155 - val_loss: 0.3304 - val_mse: 0.3304\n",
            "Epoch 25/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3180 - mse: 0.3180 - val_loss: 0.3334 - val_mse: 0.3334\n",
            "Epoch 26/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.3017 - mse: 0.3017 - val_loss: 0.3323 - val_mse: 0.3323\n",
            "Epoch 27/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2958 - mse: 0.2958 - val_loss: 0.3336 - val_mse: 0.3336\n",
            "Epoch 28/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2955 - mse: 0.2955 - val_loss: 0.3291 - val_mse: 0.3291\n",
            "Epoch 29/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2862 - mse: 0.2862 - val_loss: 0.3363 - val_mse: 0.3363\n",
            "Epoch 30/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2833 - mse: 0.2833 - val_loss: 0.3369 - val_mse: 0.3369\n",
            "Epoch 31/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2771 - mse: 0.2771 - val_loss: 0.3439 - val_mse: 0.3439\n",
            "Epoch 32/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2721 - mse: 0.2721 - val_loss: 0.3405 - val_mse: 0.3405\n",
            "Epoch 33/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2641 - mse: 0.2641 - val_loss: 0.3437 - val_mse: 0.3437\n",
            "Epoch 34/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2561 - mse: 0.2561 - val_loss: 0.3372 - val_mse: 0.3372\n",
            "Epoch 35/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2583 - mse: 0.2583 - val_loss: 0.3347 - val_mse: 0.3347\n",
            "Epoch 36/50\n",
            "17900/17900 [==============================] - 315s 18ms/step - loss: 0.2523 - mse: 0.2523 - val_loss: 0.3438 - val_mse: 0.3438\n",
            "Epoch 37/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2421 - mse: 0.2421 - val_loss: 0.3448 - val_mse: 0.3448\n",
            "Epoch 38/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2408 - mse: 0.2408 - val_loss: 0.3440 - val_mse: 0.3440\n",
            "Epoch 39/50\n",
            "17900/17900 [==============================] - 317s 18ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 0.3448 - val_mse: 0.3448\n",
            "Epoch 40/50\n",
            "17900/17900 [==============================] - 316s 18ms/step - loss: 0.2285 - mse: 0.2285 - val_loss: 0.3437 - val_mse: 0.3437\n",
            "Epoch 41/50\n",
            "10112/17900 [===============>..............] - ETA: 2:11 - loss: 0.2211 - mse: 0.2211"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}