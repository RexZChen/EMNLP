{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "goUje1DUzmLy",
        "colab_type": "code",
        "outputId": "129fcfad-03aa-45be-9694-6d0a5e0cae57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifUJWs39zoh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = pd.read_csv(\"/content/drive/Shared drives/EMNLP/full_prepped_training.csv\")\n",
        "test_file = pd.read_csv(\"/content/drive/Shared drives/EMNLP/prepped_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndau9u3nzt3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# original; edited_sentence; word_position; cosine_similarity\n",
        "def dataset_gathering(dataset):\n",
        "    # origin = dataset[\"original\"]\n",
        "    edited = dataset[\"edited_sentence\"]\n",
        "    labels = dataset[\"meanGrade\"]\n",
        "    # position = dataset[\"word_position\"]\n",
        "    # cosine = dataset[\"cosine_similarity\"]\n",
        "\n",
        "    res = []\n",
        "    for sample in zip(edited, labels):\n",
        "        res.append(sample)\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwHw6e3z4oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = dataset_gathering(train_file)\n",
        "test_file = dataset_gathering(test_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAB5wE0ez9Bb",
        "colab_type": "code",
        "outputId": "ad2caa4a-3d28-4c36-9c82-44f07381976c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_file[0])\n",
        "print(test_file[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('France is ‘ hunting down its citizens who joined twins ’ without trial in Iraq', 0.2)\n",
            "('The Latest : Election tally shows Cars turning right', 1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at40QHj20Arl",
        "colab_type": "code",
        "outputId": "bb22eb65-f58a-4fe5-9a8e-012af98b80aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print('Tokenizeing...')\n",
        "print('\\n')\n",
        "\n",
        "def tokenize(data):\n",
        "    res = []\n",
        "    for samples in data:\n",
        "        # nltk.word_tokenize用于取tokens\n",
        "        temp_t = nltk.word_tokenize(samples[0])\n",
        "        res.append([temp_t, samples[1]])\n",
        "    return res\n",
        "\n",
        "\n",
        "train_file = tokenize(train_file)\n",
        "test_file = tokenize(test_file)\n",
        "print(train_file[0])\n",
        "print(test_file[0])\n",
        "print('\\n')\n",
        "print('Tokenization completed!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizeing...\n",
            "\n",
            "\n",
            "[['France', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'Iraq'], 0.2]\n",
            "[['The', 'Latest', ':', 'Election', 'tally', 'shows', 'Cars', 'turning', 'right'], 1.2]\n",
            "\n",
            "\n",
            "Tokenization completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1HWzDL60n3G",
        "colab_type": "code",
        "outputId": "1a6e41b2-4fc0-4829-e684-f726b6bd42ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def lower_case(data):\n",
        "  print('-----Converting to lowercases-----')\n",
        "  res = []\n",
        "  temp_words = []\n",
        "  for samples in data:\n",
        "    for words in samples[0]:\n",
        "      temp_words.append(words.lower())\n",
        "    res.append([temp_words, samples[1]])\n",
        "    temp_words = []\n",
        "  print('-----Complete!-----')\n",
        "  return res\n",
        "\n",
        "train_file = lower_case(train_file)\n",
        "test_file = lower_case(test_file)\n",
        "print(train_file[0])\n",
        "print(test_file[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Converting to lowercases-----\n",
            "-----Complete!-----\n",
            "-----Converting to lowercases-----\n",
            "-----Complete!-----\n",
            "[['france', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'iraq'], 0.2]\n",
            "[['the', 'latest', ':', 'election', 'tally', 'shows', 'cars', 'turning', 'right'], 1.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoLK0ls41EI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cacluating maxlen\n",
        "def maxlen_cal(data):\n",
        "  print('-----Cacluating maxlen-----')\n",
        "  maxlen = 0\n",
        "  for samples in data:\n",
        "    temp = len(samples[0])\n",
        "    if temp >= maxlen:\n",
        "      maxlen = temp\n",
        "  print('-----Complete!-----')\n",
        "  return maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wG-T__r1Fr8",
        "colab_type": "code",
        "outputId": "457353fd-233f-49e6-95bd-97797aa702bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(maxlen_cal(train_file))\n",
        "print(maxlen_cal(test_file))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "29\n",
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpwMa7eJ1KeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_xgb6v81NAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding_len(data, maxlen):\n",
        "  print('-----Padding for dataset-----')\n",
        "  maxlen = maxlen\n",
        "  res = []\n",
        "  for samples in data:\n",
        "    temp_len = len(samples[0])\n",
        "    for k in range(maxlen - temp_len):\n",
        "      samples[0].append('.')\n",
        "    res.append([samples[0], samples[1]])\n",
        "  print('-----Complete!-----')\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nosUlX-I1PFB",
        "colab_type": "code",
        "outputId": "00935d0b-f2e6-4106-9fe1-19ecff3fb312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_file = padding_len(train_file, maxlen)\n",
        "test_file = padding_len(test_file, maxlen)\n",
        "\n",
        "print(maxlen_cal(train_file))\n",
        "print(maxlen_cal(test_file))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Padding for dataset-----\n",
            "-----Complete!-----\n",
            "-----Padding for dataset-----\n",
            "-----Complete!-----\n",
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "30\n",
            "-----Cacluating maxlen-----\n",
            "-----Complete!-----\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cguTkWZ51cc8",
        "colab_type": "code",
        "outputId": "f7840bfd-d4b9-4966-8c3a-9f98768cba9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_file[0])\n",
        "print(test_file[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['france', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'iraq', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.'], 0.2]\n",
            "[['the', 'latest', ':', 'election', 'tally', 'shows', 'cars', 'turning', 'right', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.'], 1.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckk_srDF1luF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def corpus_labels_gathering(data):\n",
        "  corpus_res = []\n",
        "  labels_res = []\n",
        "  for samples in data:\n",
        "    corpus_res.append(samples[0])\n",
        "    labels_res.append(samples[1])\n",
        "    \n",
        "  labels_res = np.array(labels_res)\n",
        "  return corpus_res, labels_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI2UeunP1r1T",
        "colab_type": "code",
        "outputId": "5d923392-289c-4014-aff5-7a5a3980f5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x_train, y_train = corpus_labels_gathering(train_file)\n",
        "x_test, y_test = corpus_labels_gathering(test_file)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(x_train[0])\n",
        "print(x_test[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17900,)\n",
            "(3024,)\n",
            "['france', 'is', '‘', 'hunting', 'down', 'its', 'citizens', 'who', 'joined', 'twins', '’', 'without', 'trial', 'in', 'iraq', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['the', 'latest', ':', 'election', 'tally', 'shows', 'cars', 'turning', 'right', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gI9-sWA2KVC",
        "colab_type": "code",
        "outputId": "41430c3d-8cef-4bc1-cd21-75be12293382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = os.path.join('/content/drive/', 'My Drive')\n",
        "embedding_dim = 300\n",
        "# Dictionary where we store the word:vector_embedding map\n",
        "embeddings_index = {}\n",
        "word_index = {}\n",
        "count=0\n",
        "\n",
        "# Setting up embedding array\n",
        "f = open(os.path.join(glove_dir, 'glove.42B.300d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float64')\n",
        "    if coefs.shape[0] != embedding_dim:\n",
        "      continue\n",
        "    # Embeddings is a dictionary of words:word_vector_embeddings\n",
        "    embeddings_index[word] = coefs\n",
        "    word_index[word] = count\n",
        "    count+=1\n",
        "f.close()\n",
        "print('Found {} word vectors.'.format(len(embeddings_index)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1917494 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Xvfo1a2QFF",
        "colab_type": "code",
        "outputId": "ba6241b9-cb3c-4a51-b310-cff639ccf318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print('Our word index dictionary is given by: (word, index), a sample 10 entries are:')\n",
        "list(word_index.items())[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our word index dictionary is given by: (word, index), a sample 10 entries are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 0),\n",
              " ('the', 1),\n",
              " ('.', 2),\n",
              " ('and', 3),\n",
              " ('to', 4),\n",
              " ('of', 5),\n",
              " ('a', 6),\n",
              " ('in', 7),\n",
              " ('\"', 8),\n",
              " ('is', 9)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRVL8ALB2U13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oov = \"OOV\"\n",
        "\n",
        "def oov_vec_gathering(embedding_dim):\n",
        "  res = np.random.rand(1, embedding_dim)\n",
        "  return res\n",
        "\n",
        "oov_vec = oov_vec_gathering(embedding_dim = embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ddWDtJQ4svj",
        "colab_type": "code",
        "outputId": "a30f3881-792d-4072-a92d-2c3848ccd019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index[oov] = oov_vec\n",
        "word_index[oov] = count + 1\n",
        "count += 1\n",
        "print('Found {} word vectors.'.format(len(embeddings_index)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1917495 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHf5PwJ6410V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Preprocessing the GloVe word-embeddings matrix --\n",
        "max_words = count\n",
        "# Instantiating a 10000 x 100 matrix \n",
        "# embedding_matrix = (number_words, dim_embedding)\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    # Make sure that we are not exceeding the max token size\n",
        "    if i < max_words:\n",
        "        # Get the embedded vector for the word\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        # Provided that a word is known store it in the \n",
        "        # embeddig matrix at position i\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca7nSwHM45Vs",
        "colab_type": "code",
        "outputId": "e1bf7f42-106a-46d2-f89b-8378d4ab6911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The size of the word embedding matrix is:\" + str(embedding_matrix.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the word embedding matrix is:(1917495, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONsASNq46qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2vec(data):\n",
        "  res = []\n",
        "  for samples in data:\n",
        "    for items in samples:\n",
        "      if items not in embeddings_index.keys():\n",
        "        word_index[items] = count\n",
        "      res.append(word_index[items])\n",
        "\n",
        "  res = np.array(res)\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa-wfMAN5AOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = data2vec(x_train)\n",
        "x_test = data2vec(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fPM_lJ15I9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(-1, maxlen)\n",
        "x_test = x_test.reshape(-1, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_eraaw50Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "        keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False),\n",
        "        # keras.layers.Bidirectional(keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=True)),\n",
        "        # keras.layers.Bidirectional(keras.layers.LSTM(1024, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=False)),\n",
        "        keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=True),\n",
        "        keras.layers.Bidirectional(keras.layers.LSTM(2048, activation='tanh', recurrent_activation='sigmoid', use_bias=True, return_sequences=False)),\n",
        "        keras.layers.Dense(1024, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(512, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(32, activation='relu'), \n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(1, activation='relu')                     \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBJMr23x58Ah",
        "colab_type": "code",
        "outputId": "291d15a1-c31a-42b5-b7e0-9775dfae5521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           575248500 \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30, 2048)          19243008  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 4096)              67125248  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 666,406,709\n",
            "Trainable params: 91,158,209\n",
            "Non-trainable params: 575,248,500\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFEnbP2p6-eG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=3e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7c19s9p7FMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=opt,\n",
        "              loss = \"mean_squared_error\",\n",
        "              metrics = ['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38NvrXrw8bjc",
        "colab_type": "code",
        "outputId": "a8dc6815-6140-47fe-a3c0-c7e514b541bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "            epochs = 10,\n",
        "            batch_size = 48,\n",
        "            validation_data = [x_test, y_test])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17900 samples, validate on 3024 samples\n",
            "Epoch 1/10\n",
            "17900/17900 [==============================] - 111s 6ms/step - loss: 0.6254 - mse: 0.6254 - val_loss: 0.4150 - val_mse: 0.4150\n",
            "Epoch 2/10\n",
            "17900/17900 [==============================] - 108s 6ms/step - loss: 0.4685 - mse: 0.4685 - val_loss: 0.3367 - val_mse: 0.3367\n",
            "Epoch 3/10\n",
            "17900/17900 [==============================] - 108s 6ms/step - loss: 0.4299 - mse: 0.4299 - val_loss: 0.3361 - val_mse: 0.3361\n",
            "Epoch 4/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.4004 - mse: 0.4004 - val_loss: 0.3150 - val_mse: 0.3150\n",
            "Epoch 5/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.3805 - mse: 0.3805 - val_loss: 0.3136 - val_mse: 0.3136\n",
            "Epoch 6/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.3164 - val_mse: 0.3164\n",
            "Epoch 7/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.3535 - mse: 0.3535 - val_loss: 0.3126 - val_mse: 0.3126\n",
            "Epoch 8/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.3416 - mse: 0.3416 - val_loss: 0.3034 - val_mse: 0.3034\n",
            "Epoch 9/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.3294 - mse: 0.3294 - val_loss: 0.3004 - val_mse: 0.3004\n",
            "Epoch 10/10\n",
            "17900/17900 [==============================] - 107s 6ms/step - loss: 0.3170 - mse: 0.3170 - val_loss: 0.3065 - val_mse: 0.3065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKcUhWPk6lMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_NN = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CzbNB496wWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = pd.read_csv(\"/content/drive/Shared drives/EMNLP/full_prepped_training.csv\")\n",
        "test_file = pd.read_csv(\"/content/drive/Shared drives/EMNLP/prepped_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCYjMxNj6zJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gathering_sml(dataset):\n",
        "    # word_position; euclidean_dist; cosine_similarity; meanGrade\n",
        "    pos = dataset[\"word_position\"]\n",
        "    dist = dataset[\"euclidean_dist\"]\n",
        "    cosine = dataset[\"cosine_similarity\"]\n",
        "    labels = dataset[\"meanGrade\"]\n",
        "\n",
        "    res = []\n",
        "    for sample in zip(pos, dist, cosine, labels):\n",
        "        res.append(sample)\n",
        "    \n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwu691YL68iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = data_gathering_sml(train_file)\n",
        "test_file = data_gathering_sml(test_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9edir-yP7Buc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attr_labels_gathering(data):\n",
        "  attr_res = []\n",
        "  labels_res = []\n",
        "  for samples in data:\n",
        "    attr_res.append(samples[:3])\n",
        "    labels_res.append(samples[-1])\n",
        "    \n",
        "  labels_res = np.array(labels_res)\n",
        "  return attr_res, labels_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InaZe-BW7EHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_, y_train_ = attr_labels_gathering(train_file)\n",
        "x_test_, y_test_ = attr_labels_gathering(test_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RblRWrIR7INx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1jcC7he7KdM",
        "colab_type": "code",
        "outputId": "5c3db754-915a-4dda-fc63-d6f116b86c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "svm_ = svm.SVR()\n",
        "svm_.fit(x_train_, y_train_)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJkxL2377vWD",
        "colab_type": "code",
        "outputId": "626afb7a-f85d-47bd-c1e1-82e1494de00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions_svm = svm_.predict(x_test_)\n",
        "print(mean_squared_error(y_test_, predictions_svm))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3446791963760914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zekLPdfD74Yn",
        "colab_type": "code",
        "outputId": "f5b72ee2-0acf-4dc8-f98d-7ab190238434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ridge_ = linear_model.Ridge(alpha=0.5)\n",
        "ridge_.fit(x_train_, y_train_)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "      normalize=False, random_state=None, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeJsfrj-8Ljl",
        "colab_type": "code",
        "outputId": "04e5d0b3-4dc4-4252-c210-c451c0496036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions_ridge = ridge_.predict(x_test_)\n",
        "print(mean_squared_error(y_test_, predictions_ridge))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.34564278233732865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6-lioDS8usC",
        "colab_type": "code",
        "outputId": "4eeeac56-1987-46d5-bcac-f41114758d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(predictions_svm))\n",
        "print(len(predictions_ridge))\n",
        "print(len(predictions_NN))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3024\n",
            "3024\n",
            "3024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWa390m9E_8",
        "colab_type": "code",
        "outputId": "f8458fe8-d7fb-490f-c8a7-3ddf8195f229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "pred_list = []\n",
        "for i in range(len(predictions_NN)):\n",
        "    temp = [np.float(predictions_NN[i]), predictions_ridge[i], predictions_svm[i]]\n",
        "    pred_list.append(temp)\n",
        "\n",
        "print(pred_list[:5])\n",
        "print(len(pred_list))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9513710737228394, 1.0949618021581715, 1.1876257231346061], [1.0973364114761353, 1.1347363731653313, 1.1888836220901866], [0.837093710899353, 1.2205052828803515, 1.24569218777683], [0.8677194714546204, 1.2233738387397715, 1.2107516530255127], [0.8231667280197144, 1.011845855375808, 0.9932851824619386]]\n",
            "3024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9kcSPS68Wss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictions_fusion(predictions_list, method=\"mean\"):\n",
        "    res = []\n",
        "    for sublist in predictions_list:\n",
        "\n",
        "        if method == \"mean\":\n",
        "            temp = np.mean(sublist)\n",
        "            res.append([temp])\n",
        "        \n",
        "        if method == \"min\":\n",
        "            temp = min(sublist)\n",
        "            res.append([temp])\n",
        "        \n",
        "        if method == \"max\":\n",
        "            temp = max(sublist)\n",
        "            res.append([temp])\n",
        "    \n",
        "    return np.array(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvRT51qk-yVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_prediction = predictions_fusion(pred_list, method=\"mean\")\n",
        "min_prediction = predictions_fusion(pred_list, method=\"min\")\n",
        "max_prediction = predictions_fusion(pred_list, method=\"max\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYRPBT6v-64j",
        "colab_type": "code",
        "outputId": "7b42dbc7-fabb-4b03-d2ca-6a7f62c85a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(np.sqrt(mean_squared_error(y_test_, mean_prediction)))\n",
        "print(np.sqrt(mean_squared_error(y_test_, min_prediction)))\n",
        "print(np.sqrt(mean_squared_error(y_test_, max_prediction)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5680877897876262\n",
            "0.5538813657680356\n",
            "0.5948010963482846\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}